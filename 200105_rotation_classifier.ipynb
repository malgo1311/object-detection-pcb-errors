{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print('ERROR!!! DIRECTORY DOESNT EXISTS -', directory)\n",
    "    else:\n",
    "        print('DIRECTORY EXISTS -', directory)\n",
    "    print()\n",
    "    \n",
    "def check_and_create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print('DIRECTORY DOESNT EXISTS -', directory)\n",
    "        os.mkdir(directory)\n",
    "        print()\n",
    "        print('DIRECTORY CREATED -', directory)\n",
    "    else:\n",
    "        print('DIRECTORY EXISTS -', directory)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_folder = \"/Users/aishwaryamalgonde/Aishwarya/nanonets\"\n",
    "os.chdir(base_folder)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = '46_n' # component type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"/Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec/\" + parent_folder\n",
    "\n",
    "run_model = \"vgg16\"\n",
    "\n",
    "import os\n",
    "# main_dir = os.path.join(parent_folder, run_model)\n",
    "check_and_create_dir(parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(parent_folder, run_model)#, \"\")\n",
    "check_and_create_dir(model_dir)\n",
    "\n",
    "os.chdir(model_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_FOLDER = '/Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec/6/6/training_data'\n",
    "\n",
    "DATA_DIR_TRAIN = os.path.join( data, \"train\")\n",
    "DATA_DIR_VAL = os.path.join(data, \"test\")\n",
    "\n",
    "check_dir(DATA_DIR_TRAIN)\n",
    "check_dir(DATA_DIR_VAL)\n",
    "\n",
    "# OUTPUT_DIR = os.path.join(os.getcwd(), \"output\")\n",
    "# check_and_create_dir(OUTPUT_DIR)\n",
    "\n",
    "# /Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec/20_f/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEL5IKrhaK62"
   },
   "source": [
    "# 2. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.image_data_format()\n",
    "K.set_image_data_format('channels_last')\n",
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Fx07wNBaPdc"
   },
   "source": [
    "# 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZRzIiPpCpB6"
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.3\n",
    "\n",
    "if run_model == \"xception\" or run_model == \"inceptionv3\":\n",
    "    img_h = 229\n",
    "    img_w = 229\n",
    "else:\n",
    "    img_h = 224\n",
    "    img_w = 224\n",
    "    \n",
    "img_c = 3\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "input_shape = (img_h, img_w, img_c)\n",
    "input_shape_hw = (img_h, img_w)\n",
    "\n",
    "checkpoint_file = run_model + \"_best_ld\"\n",
    "\n",
    "print(\"batch_size : \", batch_size)\n",
    "print(\"img_h : \", img_h)\n",
    "print(\"img_w : \", img_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_model == \"vgg16\": #     (224, 224, 3) (224,224)\n",
    "    print(\"Model : VGG16\")\n",
    "    base_model = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    \n",
    "else:\n",
    "    print(\"ERROR!!! Please select appropriate model name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "18RMvwOXsBvD",
    "outputId": "fbbe7851-83ec-4062-bb1c-f70e3f4cbce4"
   },
   "outputs": [],
   "source": [
    "x=base_model.output\n",
    "\n",
    "# x=GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# x=Dropout(dropout_rate)(x)\n",
    "\n",
    "x = Dense(1024, \n",
    "        activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(0.01), \n",
    "        kernel_initializer=glorot_uniform(seed=None))(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "\n",
    "x = Dropout(dropout_rate)(x)\n",
    "\n",
    "# x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "\n",
    "# x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "\n",
    "# x=Dropout(dropout_rate)(x)\n",
    "\n",
    "preds=Dense(1,\n",
    "            activation='sigmoid',\n",
    "#             kernel_regularizer=regularizers.l2(0.01),\n",
    "            kernel_initializer=glorot_uniform(seed=None))(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi4WUNqDChUy"
   },
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "#specify the inputs\n",
    "#specify the outputs\n",
    "#now a model has been created based on our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7I-MQxXUYh_U",
    "outputId": "a5293cc3-686c-4b97-8268-e270779ad23b"
   },
   "outputs": [],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "JesMmAatChU0",
    "outputId": "25994e14-511a-492f-9ef8-89872c39ace5"
   },
   "outputs": [],
   "source": [
    "# 87 for MobileNet\n",
    "# 780 for InceptionResNetv2\n",
    "# 19 for vgg16\n",
    "# 132 for Xception\n",
    "# 178 resnet50\n",
    "n = 19\n",
    "for layer in model.layers[:n]:\n",
    "    layer.trainable=False\n",
    "\n",
    "print(\"TRAINABLE LAYERS\")\n",
    "print()\n",
    "for layer in model.layers[n:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Augmentation\n",
    "# zoom_range = 0.4\n",
    "rotation_range = 10\n",
    "vflip = True\n",
    "# hflip = True\n",
    "# width_shift_range=0.2,\n",
    "# height_shift_range=0.2,\n",
    "shear_range=0.05,\n",
    "# width_shift_range = 0.3\n",
    "# height_shift_range = 0.3\n",
    "# preprocessing\n",
    "rescale = 1. / 255.\n",
    "preprocessing_function = None\n",
    "\n",
    "# seed = 20170804\n",
    "# batch_size = 5\n",
    "    \n",
    "# creating dictionary\n",
    "data_gen_args = dict(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rescale=rescale,\n",
    "    preprocessing_function=preprocessing_function,\n",
    "    shear_range=shear_range,\n",
    "#     zoom_range=zoom_range,\n",
    "    rotation_range=rotation_range,\n",
    "#     width_shift_range=width_shift_range,\n",
    "#     height_shift_range=height_shift_range,\n",
    "    vertical_flip=vflip,\n",
    "#     horizontal_flip=hflip)\n",
    "\n",
    "# *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions \n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=image_datagen.flow_from_directory(DATA_DIR_TRAIN, # this is where you specify the path to the main data folder\n",
    "                                                 target_size=input_shape_hw,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='binary',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(DATA_DIR_VAL, # this is where you specify the path to the validation data folder\n",
    "                                              target_size=input_shape_hw,\n",
    "                                              color_mode='rgb',\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='binary',\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2NUBV-CtChU6",
    "outputId": "e8769d72-4245-4308-9877-d19d260670ac"
   },
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "opt = Adam(lr=0.00001)\n",
    "\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING STEP SIZE FOR TRAIN AND VAL DATASET\n",
    "step_size_train = np.ceil(train_generator.n/train_generator.batch_size)\n",
    "step_size_val = np.ceil(val_generator.n/val_generator.batch_size)\n",
    "step_size_train, step_size_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the decay for the optimizer\n",
    "# decay = 0.0\n",
    "# #opt_sgd = keras.optimizers.SGD(lr=TRAIN_MAX_LR, decay=decay, momentum=0.9)\n",
    "# model.compile(optimizer=opt,\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# tensorboard_callback = TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# SAVING THE CHECKPOINT WITH LOWEST VAL_LOSS\n",
    "checkpoint = ModelCheckpoint(checkpoint_file, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1) \n",
    "                            #, save_weights_only=True)\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "H = model.fit_generator(generator = train_generator,\n",
    "                        steps_per_epoch = step_size_train,\n",
    "                        validation_data = val_generator,                              \n",
    "                        validation_steps = step_size_val,\n",
    "                        verbose = 1,epochs = TRAIN_EPOCHS,\n",
    "                        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_plot = os.path.join(os.getcwd(), \"output\", \"training_\"+schedule_type+\".png\")\n",
    "\n",
    "# # plot the training loss and accuracy\n",
    "# N = np.arange(0, TRAIN_EPOCHS)\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on CIFAR-10\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.savefig(train_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_plot = os.path.join(os.getcwd(), \"output\", \"acc_\"+schedule_type+\".png\")\n",
    "# loss_plot = os.path.join(os.getcwd(), \"output\", \"loss_\"+schedule_type+\".png\")\n",
    "# lr_plot = os.path.join(os.getcwd(), \"output\", \"lr_\"+schedule_type+\".png\")\n",
    "\n",
    "# # plot the training loss and accuracy\n",
    "# N = np.arange(0, TRAIN_EPOCHS)\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "# plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Accuracy\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.savefig(acc_plot)\n",
    "\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.title(\"Training Loss\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.savefig(loss_plot)\n",
    "\n",
    "# if schedule is not None:\n",
    "# \tschedule.plot(N)\n",
    "# \tplt.savefig(lr_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# This line must be executed before loading Keras model.\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "from keras.models import load_model\n",
    "model2 = load_model(checkpoint_file)\n",
    "print(\"[INFO] Loaded model from disk\")\n",
    "\n",
    "print(model2.outputs)\n",
    "print(model2.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSbC7ZAe_mM6"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Augmentation\n",
    "# preprocessing\n",
    "rescale = 1. / 255.\n",
    "preprocessing_function = None\n",
    "\n",
    "# seed = 20170804\n",
    "# batch_size = 5\n",
    "    \n",
    "# creating dictionary\n",
    "data_gen_args = dict(rescale=rescale,\n",
    "    preprocessing_function=preprocessing_function)\n",
    "\n",
    "# *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions \n",
    "# image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = '/Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec/6/6/0/10.jpg_6_6_0.jpg'\n",
    "image_path = ('/Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec/'+\n",
    "              parent_folder+\n",
    "              '/correct/10.jpg_20_f_0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting images\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "batch_size = 1\n",
    "img = image.load_img(image_path, target_size=(img_width, img_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x/255.\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = np.vstack([x])\n",
    "classes = model2.predict(x)\n",
    "classes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_hw = (img_height, img_width)\n",
    "\n",
    "DATA_DIR_TEST = \"/Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec/6_6/training_data/test\"\n",
    "\n",
    "## READING THE TEST DIRECTORY\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        DATA_DIR_TEST,\n",
    "        target_size=input_shape_hw,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False) \n",
    "test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "rotated = 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of keras_TL_v3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
