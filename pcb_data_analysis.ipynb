{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_folder = \"/Users/aishwaryamalgonde/Aishwarya/nanonets/data\"\n",
    "os.chdir(base_folder)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "#         print('Creating directory -', directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML to PD dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_name = '1.1.xml'\n",
    "tree = ET.parse(xml_name)\n",
    "root = tree.getroot()\n",
    "counter = 0\n",
    "for member in root.findall('object'):\n",
    "    counter += 1\n",
    "#     if int(member[3].text) == 1:\n",
    "#         name = member[0].text+':rotated'\n",
    "#     else:\n",
    "#         name = member[0].text\n",
    "        \n",
    "    pos_n = int((member[0].text).split('_')[0])\n",
    "    typec = (member[0].text).split('_')[1]\n",
    "    value = (xml_name,\n",
    "             int(member[4][0].text),\n",
    "             int(member[4][1].text),\n",
    "             int(member[4][2].text),\n",
    "             int(member[4][3].text),\n",
    "             pos_n,\n",
    "             typec,\n",
    "             int(member[3].text))\n",
    "    print(value)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "#     xml_list_2 = []\n",
    "    counter = 0\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        xml_file_name = xml_file.split(\"/\")[-1].split('.xml')[0]+'.jpg'\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        counter += 1\n",
    "        print(xml_file)\n",
    "        for member in root.findall('object'):\n",
    "            if int(member[3].text) == 1:\n",
    "                name = member[0].text+':rotated'\n",
    "            else:\n",
    "                name = member[0].text\n",
    "            pos_n = int((member[0].text).split('_')[0])\n",
    "            typec = (member[0].text).split('_')[1]\n",
    "            value = (xml_file_name,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text),\n",
    "                     pos_n,\n",
    "                     typec,\n",
    "                     int(member[3].text))\n",
    "            xml_list.append(value)\n",
    "#             value_2 = (xml_file_name,\n",
    "#                  int(member[4][0].text),\n",
    "#                  int(member[4][1].text),\n",
    "#                  int(member[4][2].text),\n",
    "#                  int(member[4][3].text),\n",
    "#                  name)\n",
    "#             xml_list_2.append(value_2)\n",
    "    # column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    column_name = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'pos_n', 'typec', 'rotated']\n",
    "#     column_name_2 = ['filename', 'xmin', 'ymin', 'xmax', 'ymax','class_2']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "#     xml_df_2 = pd.DataFrame(xml_list_2, columns=column_name_2)\n",
    "    print(\"Scanned Files :\", counter)\n",
    "    return xml_df#, xml_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in ['train']:\n",
    "    working_directory = os.path.join(base_folder, directory)\n",
    "    xml_df = xml_to_csv(base_folder)\n",
    "#     xml_df.to_csv(working_directory + '_labels.csv', index=None)\n",
    "#     xml_df_2.to_csv(working_directory + '_rotated_labels.csv', index=None)\n",
    "\n",
    "#     data = csv_to_txt(xml_df)\n",
    "#     data.to_csv(working_directory + '_annotate.txt', header=None, index=None, sep=' ')\n",
    "    \n",
    "#     data = csv_to_txt(xml_df_2)\n",
    "#     data.to_csv(working_directory + '_rotated_annotate.txt', header=None, index=None, sep=' ')\n",
    "\n",
    "    # xml_df.to_csv('{}_labels.csv'.format(directory), index=None)\n",
    "    print('Successfully converted xml to csv to txt - {}'.format(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pos_n', 'typec']\n",
    "xml_df['component'] = xml_df[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components = (list(set(list(xml_df['component']))))\n",
    "all_image_name = list(set(list(xml_df['filename'])))\n",
    "len(all_image_name), len(all_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_position = []\n",
    "counter = 0\n",
    "for c in all_components:\n",
    "#     print(c)\n",
    "    groupby_component = xml_df.loc[xml_df['component'] == c]\n",
    "    \n",
    "    ## Finding average postion\n",
    "    xmin_avg = int(groupby_component['xmin'].mean())\n",
    "    ymin_avg = int(groupby_component['ymin'].mean())\n",
    "    xmax_avg = int(groupby_component['xmax'].mean())\n",
    "    ymax_avg = int(groupby_component['ymax'].mean())\n",
    "    \n",
    "    value = (c, xmin_avg, ymin_avg, xmax_avg, ymax_avg)\n",
    "    avg_position.append(value)\n",
    "    counter += 1\n",
    "#     print(groupby_component)\n",
    "    \n",
    "#     if counter>0:\n",
    "#         break\n",
    "column_name = ['component', 'xmin_avg', 'ymin_avg', 'xmax_avg', 'ymax_avg']\n",
    "avg_position_df = pd.DataFrame(avg_position, columns=column_name)\n",
    "print(counter)\n",
    "avg_position_df.to_csv('avg_positions_of_components.csv', index=None)\n",
    "# avg_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(list(xml_df['combined'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(((xml_df['filename']))),len(set(list(xml_df['filename']))),len(set(list(xml_df['pos_n']))),len(set(list(xml_df['typec'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Image - Similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "#s = ssim(imageA, imageB)\n",
    "# s = measure.compare_ssim(imageA, imageB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    # NOTE: the two images must have the same dimension\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "    # the two images are\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_c = 'h'\n",
    "pos = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_24_h_df = xml_df.loc[xml_df['pos_n'] == pos]\n",
    "len(set(_24_h_df['filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding average postion\n",
    "xmin_avg = int(_24_h_df['xmin'].mean())\n",
    "ymin_avg = int(_24_h_df['ymin'].mean())\n",
    "xmax_avg = int(_24_h_df['xmax'].mean())\n",
    "ymax_avg = int(_24_h_df['ymax'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_image_name:\n",
    "#     print(i)\n",
    "    if i not in list(set(list(_24_h_df['filename']))):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding for missing components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_components_list = ['29_i', '30_i']\n",
    "missing_components_list = ['3_b', '4_b', '33_e', '20_f', '25_f', '24_h', '28_i', '29_i', '30_i', \n",
    "                           '45_i', '47_n', '48_n', '11_q', '13_s', '42_z',\n",
    "                           '53_ac', '55_l', '56_ae', '57_af']\n",
    "missing_threshold = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imagehash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_components in missing_components_list:\n",
    "    component_df = xml_df.loc[xml_df['component'] == missing_components]\n",
    "\n",
    "    ref_img = cv2.imread('10.jpg')\n",
    "\n",
    "    position = avg_position_df.loc[avg_position_df['component'] == missing_components]\n",
    "    xmin_avg = int(position['xmin_avg'].mean())\n",
    "    ymin_avg = int(position['ymin_avg'].mean())\n",
    "    xmax_avg = int(position['xmax_avg'].mean())\n",
    "    ymax_avg = int(position['ymax_avg'].mean())\n",
    "\n",
    "    ref_crop = ref_img[ymin_avg:ymax_avg, xmin_avg:xmax_avg, :]\n",
    "    ref_crop_1 = Image.fromarray(ref_crop)\n",
    "    ref_crop_1_hash = imagehash.average_hash(ref_crop_1)\n",
    "    \n",
    "    present = []\n",
    "    absent = []\n",
    "\n",
    "    print(missing_components)\n",
    "    for image_name in all_image_name:\n",
    "        \n",
    "        test_img = cv2.imread(image_name)\n",
    "        test_crop = test_img[ymin_avg:ymax_avg, xmin_avg:xmax_avg, :]\n",
    "        \n",
    "        ref_mean = np.mean(ref_crop, axis = 2)\n",
    "        test_mean = np.mean(test_crop, axis = 2)\n",
    "        output = abs(np.mean(ref_mean-test_mean))\n",
    "        \n",
    "#         output = mse(ref_crop, test_crop)\n",
    "        \n",
    "        if image_name not in list(set(list(component_df['filename']))):\n",
    "            print('Missing_images', image_name) \n",
    "            absent.append(output)\n",
    "        else:\n",
    "            present.append(output)\n",
    "    \n",
    "    threshold = (statistics.mean(absent)+statistics.mean(present))/2\n",
    "    missing_threshold[missing_components] = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_threshold_copy = missing_threshold\n",
    "missing_threshold_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('missing_threshold_mean.txt', 'wb') as handle:\n",
    "  pickle.dump(missing_threshold_copy, handle)\n",
    "\n",
    "with open('missing_threshold_mean.txt', 'rb') as handle:\n",
    "  missing_threshold_read = pickle.loads(handle.read())\n",
    "\n",
    "print (missing_threshold_copy == missing_threshold_read) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_threshold_read['3_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(crop_ref_2, crop_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure.compare_ssim(crop_ref_2, crop_ref, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crop regions from above images\n",
    "image = cv2.imread('2.jpg')\n",
    "crop_ref_2 = image[ymin_avg:ymax_avg, xmin_avg:xmax_avg, :]\n",
    "plt.imshow(crop_ref_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crop regions from above images\n",
    "image = cv2.imread('1.jpg')\n",
    "crop_ref = image[ymin_avg:ymax_avg, xmin_avg:xmax_avg, :]\n",
    "plt.imshow(crop_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crop regions from above images\n",
    "image = cv2.imread('15.15.jpg')\n",
    "crop = image[ymin_avg:ymax_avg, xmin_avg:xmax_avg, :]\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating component crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_flag(rotated):\n",
    "    if rotated==0:\n",
    "        return 'correct'\n",
    "    else:\n",
    "        return 'rotated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_components = ['6_6', '20_f', '25_f', '28_i', '30_i', '36_i', '45_i', '44_m', \n",
    "                      '46_n', '51_n', '47_n', '48_n', '60_o', '13_s', '27_x', '42_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in rotated_components:\n",
    "    component = c\n",
    "    print(c)\n",
    "    i_df = xml_df.loc[xml_df['component'] == component]\n",
    "    print(len(i_df['component']))\n",
    "    counter = 0\n",
    "    for index, row in i_df.iterrows():\n",
    "#         print(row['filename'])\n",
    "        image = cv2.imread(row['filename'])\n",
    "        crop = image[row['ymin']:row['ymax'], row['xmin']:row['xmax'], :]\n",
    "\n",
    "\n",
    "        path = os.path.join(os.getcwd(), 'split_typec', row['component'], rotation_flag(row['rotated']))\n",
    "        check_dir(path)\n",
    "\n",
    "        name = row['filename']+'_'+row['component']+'_'+str(row['rotated'])+'.jpg'\n",
    "        image_path = os.path.join(path, name)\n",
    "\n",
    "        counter += 1\n",
    "        cv2.imwrite(image_path, crop)\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test vs train folder for each rotated component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print('DIRECTORY DOESNT EXISTS -', directory)\n",
    "        os.mkdir(directory)\n",
    "        print()\n",
    "        print('DIRECTORY CREATED -', directory)\n",
    "    else:\n",
    "        shutil.rmtree(directory)\n",
    "        os.mkdir(directory)\n",
    "        print('DIRECTORY EXISTS. Deleted. Created New -', directory)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/Users/aishwaryamalgonde/Aishwarya/nanonets/data/split_typec'\n",
    "os.chdir(base_folder)\n",
    "os.getcwd()\n",
    "\n",
    "from glob import glob\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_components = ['6_6', '20_f', '25_f', '28_i', '30_i', '36_i', '45_i', '44_m', \n",
    "                      '46_n', '51_n', '47_n', '48_n', '60_o', '13_s', '27_x', '42_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component = '44_m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(component, 'train')\n",
    "test_path = os.path.join(component, 'test')\n",
    "\n",
    "check_and_create_dir(train_path)\n",
    "check_and_create_dir(test_path)\n",
    "\n",
    "train_path_rotated = os.path.join(component, 'train', 'rotated')\n",
    "test_path_rotated = os.path.join(component, 'test', 'rotated')\n",
    "\n",
    "check_and_create_dir(train_path_rotated)\n",
    "check_and_create_dir(test_path_rotated)\n",
    "\n",
    "train_path_correct = os.path.join(component, 'train', 'correct')\n",
    "test_path_correct = os.path.join(component, 'test', 'correct')\n",
    "\n",
    "check_and_create_dir(train_path_correct)\n",
    "check_and_create_dir(test_path_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotated\n",
    "rotated_path = os.path.join(component, 'rotated')\n",
    "all_images = glob(os.path.join(rotated_path,'*.jpg'))\n",
    "all_images\n",
    "for image_path in all_images:\n",
    "    image = cv2.imread(image_path)\n",
    "    name = image_path.split('/')[-1]\n",
    "\n",
    "    path = os.path.join(train_path_rotated, name)\n",
    "    cv2.imwrite(path, image)\n",
    "    \n",
    "    path = os.path.join(test_path_rotated, name)\n",
    "    cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct\n",
    "train_n = 18\n",
    "test_n = 4\n",
    "\n",
    "correct_path = os.path.join(component, 'correct')\n",
    "all_images = glob(os.path.join(correct_path,'*.jpg'))\n",
    "shuffle(all_images)\n",
    "print(len(all_images))\n",
    "\n",
    "for image_path in all_images[:train_n]:\n",
    "    image = cv2.imread(image_path)\n",
    "    name = image_path.split('/')[-1]\n",
    "\n",
    "    path = os.path.join(train_path_correct, name)\n",
    "    cv2.imwrite(path, image)\n",
    "    \n",
    "for image_path in all_images[train_n:train_n+test_n]:\n",
    "    image = cv2.imread(image_path)\n",
    "    name = image_path.split('/')[-1]\n",
    "    \n",
    "    path = os.path.join(test_path_correct, name)\n",
    "    cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(all_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
